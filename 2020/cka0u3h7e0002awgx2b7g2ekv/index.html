<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8" />
   
  <meta name="keywords" content="����,����,����,˼��,����" />
   
  <meta name="description" content="�������" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1" />
  <title>
    Deep learning Overview |  ��
  </title>
  <meta name="generator" content="hexo-theme-yilia-plus">
  
  <link rel="shortcut icon" href="/favicon.ico" />
  
  
<link rel="stylesheet" href="/css/style.css">

  
<script src="/js/pace.min.js"></script>


  

  

<link rel="alternate" href="/atom.xml" title="��" type="application/atom+xml">
</head>

</html>

<body>
  <div id="app">
    <main class="content">
      <section class="outer">
  <article id="post-Deep Learning Overview" class="article article-type-post" itemscope
  itemprop="blogPost" data-scroll-reveal>

  <div class="article-inner">
    
    <header class="article-header">
       
<h1 class="article-title sea-center" style="border-left:0" itemprop="name">
  Deep learning Overview
</h1>
  

    </header>
    

    
    <div class="article-meta">
      <a href="/2020/cka0u3h7e0002awgx2b7g2ekv/" class="article-date">
  <time datetime="2020-02-29T16:00:00.000Z" itemprop="datePublished">2020-03-01</time>
</a>
      
  <div class="article-category">
    <a class="article-category-link" href="/categories/%E5%AD%A6%E4%B9%A0/">学习</a>
  </div>

      
      
<div class="word_count">
    <span class="post-time">
        <span class="post-meta-item-icon">
            <i class="ri-quill-pen-line"></i>
            <span class="post-meta-item-text"> 字数统计:</span>
            <span class="post-count">3.2k字</span>
        </span>
    </span>

    <span class="post-time">
        &nbsp; | &nbsp;
        <span class="post-meta-item-icon">
            <i class="ri-book-open-line"></i>
            <span class="post-meta-item-text"> 阅读时长≈</span>
            <span class="post-count">11分钟</span>
        </span>
    </span>
</div>

      
    </div>
    

    
    
    <div class="tocbot"></div>





    

    
    <div class="article-entry" itemprop="articleBody">
      


      

      
      <h2 id="Deep-Learning-Overview"><a href="#Deep-Learning-Overview" class="headerlink" title="Deep Learning Overview"></a><center>Deep Learning Overview</center></h2><p>深度学习(Deep Learning)，是一种学习算法(Learning Algorithm)，亦是人工智能(Artificial Intelligence)领域的一个重要分支。经过快速发展，深度学习渐渐形成了一种从训练数据出发，经过一个端到端(end-to-end)的模型，然后直接输出得到最终结果的一种新模式。</p>
<a id="more"></a>

<h3 id="一-概述"><a href="#一-概述" class="headerlink" title="一. 概述"></a>一. 概述</h3><p>图灵测试，是图灵在1950年的论文中提出的设想，即，隔墙对话，你将不知道与你谈话的是人还是电脑，这个给计算机，尤其是人工智能(Artificial Intelligence,AI)预设了一个很高的期望值。</p>
<p>但是直到2006年以来，机器学习领域取得的突破性进展，让人们意识到图灵试验，至少不是那么可望而不可及了。至于技术手段，不仅仅依赖于云计算对大数据的并行处理能力，而且依赖于算法，这个算法就是Deep Learning。借助于Deep Learning算法，人类终于找到了如何处理==”抽象概念”==这个难题。</p>
<p>2012年6月，《纽约时报》披露了Google Brain项目，由著名的斯坦福大学的机器学习教授Andrew Ng和在大规模计算机系统方面的世界顶尖专家Jeff Dean共同主导，用16000个CPU Core的并行计算平台训练一种称为“深度神经网络”(DNN, Deep Neutral Networks)的机器学习模型(内部共有10亿个节点)，在语音识别和图像识别等领域获得了巨大的成功。</p>
<p>项目负责人之一Andrew称：“我们没有像通常那样自己框定边界，而是直接把海量数据投放到算法中，让数据自己说话，系统会自动从数据中学习。”另一名负责人Jeff说：“我们在训练的时候从来不会告诉机器说：‘这是一只猫。’系统其实是自己发明或者领悟了‘猫’的概念。”</p>
<h3 id="二-背景"><a href="#二-背景" class="headerlink" title="二. 背景"></a>二. 背景</h3><p>机器学习(Machine Learning)是一种专门研究计算机怎样模拟或实现人类的学习行为，以获得新的知识或技能，重新组织已有的知识结构使之不断改善自身的性能的学科。机器能否向人类一样具有学习能力呢？1959年美国的Samuel设计了一个下棋的程序，这个程序具有学习能力，可以在不断的对弈中改善自己的棋艺。</p>
<p>机器学习在发展过程中，还存在很多没有良好解决的问题：</p>
<div align="center">
    <img src="https://raw.githubusercontent.com/TaylorWon/ImageBed/master/img/DL/2_background_issues_001.png" style="zoom:40%">
</div>



<p>如图像识别、语音识别、自然语言理解、天气预测、基因表达、内容推荐等。目前我们通过机器学习去解决这些问题的思路都是这样的(以视觉感知为例):</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">graph LR</span><br><span class="line">A[Low-level sensing] --&gt;B[Pre-processing]</span><br><span class="line">B[Pre-processing] --&gt;C[Feature extract]</span><br><span class="line">C[Feature extract] --&gt;D[Feature selection]</span><br><span class="line">D[Feature selection] --&gt;E[Inference,prediction,recognition]</span><br></pre></td></tr></table></figure>

<p>从开始的通过传感器获得数据，然后经过预处理、特征提取、特征选择，再到推理、预测或者识别。最后一个部分是机器学习的部分。中间的三个部分，概括起来就是特征表达。良好特征表达，对最终算法的准确性起了非常关键的作用，而且系统主要的计算和测试工作都耗在了这一部分。目前这一部分都是人工完成的，靠人工提取特征。即：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">graph LR</span><br><span class="line">A[Input] --&gt;B[Feature Representation,SIFT&#x2F;HoG.]</span><br><span class="line">B[Feature Representation,SIFT&#x2F;HoG.] --&gt;C[Learning Algorithm]</span><br></pre></td></tr></table></figure>

<p>其中，好的特性具有不变性(大小、尺度和旋转等)和可区分性。例如，Sift的出现，对尺度、旋转以及一定视角和光照变化等图像变化都具有不变性，且具有很强的可区分性，是局部图像特征描述子研究领域一项里程碑式的工作。</p>
<p>在这个工作中，手工选取特征是一件非常费力、启发式的方法，同时手工选取特征不太好，那么能不能自动地学习一些特征呢？答案是能！Deep Learning就是用来解决这个问题的，即进行Unsupervised Feature Learning，不要人参与的特征选取过程。</p>
<h3 id="三-人脑视觉机理"><a href="#三-人脑视觉机理" class="headerlink" title="三. 人脑视觉机理"></a>三. 人脑视觉机理</h3><p>1981年的诺贝尔医学奖，颁发给了David Hubel和Torsten Wiesel, 以及Roger Sperry。前两位的主要贡献，是“发现了视觉系统的信息处理”：可视皮层是分级的，即人的视觉系统的信息处理是分级的。神经-中枢-大脑的工作过程，或许是一个不断迭代，不断抽象的过程。从原始信号，做低级抽象，逐渐向高级抽象迭代，人类的逻辑思维，经常使用高度抽象的概念。</p>
<div align="center">
    <img src="https://raw.githubusercontent.com/TaylorWon/ImageBed/master/img/DL/3_brainvision_001.png" style="zoom:40%">
</div>

<p>从低级的V1区提取边缘特征，再到V2区的形状或者目标的部分等，再到更高层，整个目标、目标的行为等。高层的特征是低层特征的组合，从低层到高层的特征表示越来越抽象，越来越能表现语义或者意图。这里面有个关键词：==分层==。</p>
<p>而Deep Learning的deep就是表示存在多少层。同时学习的是特征的表达，所以关于特征或者这个层级特征，需要进行深入的了解。</p>
<h3 id="四-关于特征"><a href="#四-关于特征" class="headerlink" title="四. 关于特征"></a>四. 关于特征</h3><p>特征是机器学习系统的原材料，如果数据被很好的表达成了特征，通常线性模型就能达到满意的精度。</p>
<h4 id="4-1-特征表示的粒度"><a href="#4-1-特征表示的粒度" class="headerlink" title="4.1. 特征表示的粒度"></a>4.1. 特征表示的粒度</h4><p>学习算法在一个什么粒度上的特征表示，才能发挥作用？对于一个图片，像素级的特征根本没有价值，比如区分一张图片是什么的时候。如果一个特征是一个具有结构性(或者说含义)的时候，就很容易区分出图片中的内容，学习算法才能发挥作用。</p>
<div align="center">
    <img src="https://raw.githubusercontent.com/TaylorWon/ImageBed/master/img/DL/4_features_01_001.png" style="zoom:40%">
</div>



<h4 id="4-2-初级-浅层-特征表示"><a href="#4-2-初级-浅层-特征表示" class="headerlink" title="4.2. 初级(浅层)特征表示"></a>4.2. 初级(浅层)特征表示</h4><p>既然像素级的特征表示方法没有作用，那怎么样的表示才有用呢？</p>
<p>稀疏编码(sparse coding)，是一个重复迭代的过程，每次迭代分为两步，经过几次迭代后，选出最佳的组合解，而这个组合解基本上都是图片上不同物体上的边缘线。</p>
<p>复杂的图形，往往是由一些基本结构组成。声音也是这样，可以由基本的结构合成。</p>
<h4 id="4-3-结构性特征表示"><a href="#4-3-结构性特征表示" class="headerlink" title="4.3. 结构性特征表示"></a>4.3. 结构性特征表示</h4><p>小块的图形可以由基本的edge构成，更结构化、更复杂的、具有概念性的图形是如何表示呢？这就需要更高层次的特征表示比如V2，V4。</p>
<p>因此，V1看像素级是像素级，V2看V1是像素级，这个是层次递进的，高层表达由低层表达的组合而成，即基basis。V1层得到的basis是边缘，然后V2层是V1层这些basis的组合，这时候V2层得到的又是高一层的basis。直观上说，就是找到make sense的小patch再将其进行combine，就得到了上一层的feature，递归地向上learning feature。</p>
<div align="center">
    <img src="https://raw.githubusercontent.com/TaylorWon/ImageBed/master/img/DL/4_features_03_001.png" style="zoom:40%">
</div>



<h4 id="4-4-需要有多少个特征？"><a href="#4-4-需要有多少个特征？" class="headerlink" title="4.4. 需要有多少个特征？"></a>4.4. 需要有多少个特征？</h4><p>我们需要层次的特征构建，由浅入深，但是每一层该有多少个特征呢？</p>
<p>任何一种方法，特征越多，给出的参考信息就越多，准确性就会得到提升。但是特征多意味着计算复杂，探索空间大，可以用来训练的数据在每个特征上就会稀疏，都会带来各种问题，并不一定特征越多越好。</p>
<p>此时可以聊到了Deep Learning，deep learning需要多层来获得更抽象的特征表达。那么多少层才合适呢？用什么架构来建模呢？怎么进行非监督训练呢？</p>
<h3 id="五-Deep-Learning的基本思想"><a href="#五-Deep-Learning的基本思想" class="headerlink" title="五. Deep Learning的基本思想"></a>五. Deep Learning的基本思想</h3><p>假如我们有一个系统S，它有n层(S1,S2,…Sn)，它的输入是I，输出是O，形象地表示为：<br>$$<br>I =&gt;S_1 =&gt;S_2=&gt; …… =&gt;S_n=&gt;O<br>$$<br>如果输出O等于输入I，即输入I经过这个系统变化之后没有任何信息损失(实际上信息是逐层丢失的)，设处理a信息得到b，再对b处理得到c，那么可以证明: a和c的互信息不会超过a和b的互信息。这表明信息处理不会增加信息，大部分处理会丢失信息。当然了，如果丢掉的是没用的信息，那么它保持了不变，这意味着输入I经过每一层Si都没有任何的信息损失，即在任何一层Si，它都是原有信息(输入I)的另一种表示。</p>
<p>在Deep Learning中，我们需要自动地学习特征，假设我们有一堆输入I(一堆图像或文本)，假设我们设计了一个系统S(有n层)，通过调整系统中参数，使得它的输出仍然是输入I，那么我们就可以自动地获取到输入I的一系列层次特征，即S1，S2，…Sn。</p>
<p>对于深度学习来说，其思想就是对堆叠多个层，也就是说这一层的输出作为下一层的输入，通过这种方式，就可以实现对输入信息进行分级表达了。同时在输出和输入之间的差别尽可能的小即可。</p>
<h3 id="六-浅层学习和深度学习"><a href="#六-浅层学习和深度学习" class="headerlink" title="六. 浅层学习和深度学习"></a>六. 浅层学习和深度学习</h3><p><strong>浅层学习(Shallow Laerning)是机器学习的第一次浪潮</strong></p>
<p>20世纪80年代末期，用于人工神经网络的==反向传播算法(Back Propagation,BP算法)==的发明，掀起了基于统计模型的机器学习热潮。人民发现，利用BP算法可以让一个人工神经网络模型从大量训练样本中学习统计规律，从而对未知事件做预测。这个时候的人工神经网络，虽然也被称为多层感知器(Mulit-layer Perceptron)，但实际上是只含有一层隐层节点的浅层模型。</p>
<p>20世纪90年代，各种各样的浅层机器学习模型被提出来，例如支撑向量机(SVM,Support Vector Machines)，Boosting，最大熵方法(如LR, Logistic Regression)等。这些模型的结构基本上可以看成带有一层隐层节点(如SVM,Boosting)，或没有隐层节点(如LR)。</p>
<p><strong>深度学习(Deep Learning)是机器学习的第二次浪潮</strong></p>
<p>2006年，多伦多大学 Geoffery Hinton和他的学生Ruslan Salakhutdinov在《科学》上发表了文章，开启了深度学习在学术界和工业界的浪潮。该文章的两个主要观点：</p>
<ul>
<li>多隐层的人工神经网络具有优异的特征学习能力，学习得到的特征对数据有更本质的刻画，从而有利于可视化或分类。</li>
<li>深度神经网络在训练上的难度，可以通过”逐层初始化”(layer-wise pre-training)来有效克服，在这篇文章中，逐层初始化是通过无监督学习实现的。</li>
</ul>
<p>当前多数分类、回归等学习方法为浅层结构算法，其局限性在于有限样本和计算单元情况下对复杂函数的表达能力有限。深度学习可通过学习一种深层非线性网络结构，实现复杂函数逼近。</p>
<div align="center">
    <img src="https://raw.githubusercontent.com/TaylorWon/ImageBed/master/img/DL/6_deeplearning_comparision_001.png" style="zoom:40%">
</div>

<p>深度学习的实质，是通过构建具有很多隐层的机器学习模型和海量的训练数据，来学习更有用的特征，从而最终提升分类或预测的准确性。因此，”深度模型”是手段，”特征学习”是目的。</p>
<p>区别于传统的浅层学习，深度学习的不同在于：</p>
<ol>
<li>强调了模型结构的深度，通常有5层、6层，甚至10多层的隐层节点。</li>
<li>明确突出了特征学习的重要性，也就是说，通过逐层特征变换，将样本在原空间的特征表示变换到一个新特征空间，从而使分类或预测更加容易。</li>
<li>利用大数据学习特征，能够刻画数据的丰富内在信息。</li>
</ol>
<h3 id="七-Deep-Learning-与Neutral-Network"><a href="#七-Deep-Learning-与Neutral-Network" class="headerlink" title="七. Deep Learning 与Neutral Network"></a>七. Deep Learning 与Neutral Network</h3><div align="center">
    <img src="https://raw.githubusercontent.com/TaylorWon/ImageBed/master/img/DL/7_deeplearning_introduction_001.png" style="zoom:40%">
</div>

<p>深度学习是机器学习研究中的一个新的领域，其动机在于建立、模拟人脑进行分析学习的神经网络，它模仿人脑的机制来解释数据。深度学习是无监督学习的一种。</p>
<p>深度学习的概念源于人工神经网络的研究，含有多隐层的多层感知器就是一种深度学习结构。深度学习通过组合低层特征形成更加抽象的高层表示属性类别或者特征，以发现数据的分布式特征表示。</p>
<p>Deep learning与传统的神经网络之间的相同地方和不同的地方。</p>
<div align="center">
    <img src="https://raw.githubusercontent.com/TaylorWon/ImageBed/master/img/DL/7_deeplearning_introduction_002.png" style="zoom:40%"
</div>

<p>二者的相同在与deep learning采用了神经网络相似的分层结构，系统由包括输入层、隐层(多层)、输出层组成的多层网络，只有相邻节点之间有连接，同一层以及跨层节点之间相互无连接，每一层可以看做是一个logistic regression模型，这种分层结构，是比较接近人类大脑的结构的。</p>
<p>不同的是，为了克服神经网络训练中的问题，DL采用了与神经网络很不同的训练机制。传统的神经网络中，采用的是back propagation的方式进行的，简单来讲就是采用迭代的算法来训练整个网络，随机设定初值，计算当前网络的输出，然后根据当前输出和label之间的差来改变前面各层的参数，直到收敛(整体是一个梯度下降法)。而DL整体上是一个layer-wise的训练机制。</p>
<h3 id="八-Deep-Laerning训练过程"><a href="#八-Deep-Laerning训练过程" class="headerlink" title="八. Deep Laerning训练过程"></a>八. Deep Laerning训练过程</h3><h4 id="8-1-传统神经网络的训练方法为什么不能用在深度神经网络"><a href="#8-1-传统神经网络的训练方法为什么不能用在深度神经网络" class="headerlink" title="8.1. 传统神经网络的训练方法为什么不能用在深度神经网络"></a>8.1. 传统神经网络的训练方法为什么不能用在深度神经网络</h4><p>BP算法作为传统训练多层网络的典型算法，存在的问题：</p>
<ul>
<li>梯度越来越稀疏，从顶层越往下，误差校正信号越来越小</li>
<li>收敛到局部最小值，尤其是从远离最优区域开始的时候(随机值初始化会导致这种情况发生)</li>
<li>一般只能用有标签的数据来训练，是大部分的数据是没有标签的，而大脑可以从没有标签的数据中学习</li>
</ul>
<h4 id="8-2-deep-learning训练过程"><a href="#8-2-deep-learning训练过程" class="headerlink" title="8.2. deep learning训练过程"></a>8.2. deep learning训练过程</h4><p>2006年，Hilton提出了在非监督数据上建立多层神经网络的一个有效方法。简单的说，分为两步，一是每次训练一层网络，二是调优，使原始表示x向上生成的高级表示r和该高级表示r向下生成的x’尽可能一致。方法是：</p>
<ul>
<li>首先逐层构建单程神经元，这样每次都是训练一个单层网络</li>
<li>当所有层训练完后，Hilton使用wake-sleep算法进行调优</li>
</ul>
<p>将除最顶层的其他层间的权重变成双向的，这样最顶层仍然是一个单层神经网络，而其他层则变成了图模型。向上的权重用于“认知”，向下的权重用于“生成”。然后使用wake-sleep算法调整所有的权重。让认知和生成达成一致，也就是保证生成的最顶层表示能够尽可能正确的复原底层的结点。</p>
<p><strong>Wake阶段</strong>：认知过程，通过外界的特征和向上的权重（认知权重）产生每一层的抽象表示（结点状态），并且使用梯度下降修改层间的下行权重（生成权重）。也就是“如果现实跟我想象的不一样，改变我的权重使得我想象的东西就是这样的。”</p>
<p><strong>Sleep阶段</strong> ：生成过程，通过顶层表示和向下权重，生成底层的状态，同时修改层间向上的权重。也就是“如果梦中的景象不是我脑中的相应概念，改变我的认知权重使得这种景象在我看来就是这个概念。”</p>
<p><strong>deep learning训练过程具体如下</strong></p>
<ul>
<li>使用自下上升非监督学习（就是从底层开始，一层一层的往顶层训练）：</li>
</ul>
<p>采用无标定数据（有标定数据也可）分层训练各层参数，这一步可以看作是一个无监督训练过程，是和传统神经网络区别最大的部分（这个过程可以看作是feature learning过程）。</p>
<p>具体的，先用无标定数据训练第一层，训练时先学习第一层的参数（这一层可以看作是得到一个使得输出和输入差别最小的三层神经网络的隐层），由于模型capacity的限制以及稀疏性约束，使得得到的模型能够学习到数据本身的结构，从而得到比输入更具有表示能力的特征；在学习得到第n-1层后，将n-1层的输出作为第n层的输入，训练第n层，由此分别得到各层的参数。</p>
<ul>
<li>自顶向下的监督学习（就是通过带标签的数据去训练，误差自顶向下传输，对网络进行微调）：</li>
</ul>
<p>基于第一步得到的各层参数进一步fine-tune整个多层模型的参数，这一步是一个有监督训练过程；第一步类似神经网络的随机初始化初值过程，由于DL的第一步不是随机初始化，而是通过学习输入数据的结构得到的，因而这个初值更接近全局最优，从而能够取得更好的效果；所以deep learning效果好很大程度上归功于第一步的feature learning过程。</p>
<h3 id="九-Deep-Learning的常用模型和方法"><a href="#九-Deep-Learning的常用模型和方法" class="headerlink" title="九. Deep Learning的常用模型和方法"></a>九. Deep Learning的常用模型和方法</h3><h4 id="9-1-Auto-Encoder自动编码器"><a href="#9-1-Auto-Encoder自动编码器" class="headerlink" title="9.1. Auto Encoder自动编码器"></a>9.1. Auto Encoder自动编码器</h4><p><strong>Auto Encoder自动编码器</strong></p>
<p>Deep Learning最简单的一种方法是利用人工神经网络的特点，如果给定一个神经网络，我们假设其输出和输入是相同的，然后训练调整其参数，得到每一层中的权重。自然地，我们就得到了输入I的几种不同的表示(每一层代表一种表示)，这些表示就是特征。</p>
<p>自动编码器就是一种尽可能复现输入信号的神经网络。为了实现这种复现，自动编码器就必须捕捉可以代表输入数据的重要的因素，找到可以代表原信息的主要成分。</p>
<p>具体过程简单如下：</p>
<p><strong>1）给定无标签数据，用非监督学习学习特征</strong></p>
<div align="center">
    <img src="https://raw.githubusercontent.com/TaylorWon/ImageBed/master/img/DL/9_modal_1_autoencoder_001.png" style="zoom:40%"
</div>

<p>上图中，左边的图表示的是之前的神经网络，输入的样本是有标签的，即(input, target)，这样我们根据当前输出和target(label)之间的差去改变前面各层的参数，直到收敛。而在deeplearnign模型中，只有无标签数据，即上图的右边的表示，那么这个误差是怎么得到的呢？</p>
<div align="center">
    <img src="https://raw.githubusercontent.com/TaylorWon/ImageBed/master/img/DL/9_modal_1_autoencoder_002.png" style="zoom:40%"
</div>

<p>如上图所示，我们将Input输入一个encoder编码器中，就会得到一个code，这个code也就是输入的一个表示。然后我们加一个decoder解码器，这时候decoder就会输出一个信息。如果输出的这个信息和一开始的输入信号Input很想的话，那很明显，我们有理由相信这个code是靠谱的。所以，我们就可以通过调整encoder和decoder的参数，使得重构误差最小，这时候我们就得到了输入input信号的第一个表示了，也就是编码code了。因为是无标签数据，所以误差的来源就是直接重构后与原输入相比得到。</p>
<p><strong>2）通过编码器产生特征，然后训练下一层，这样逐层训练</strong></p>
<div align="center">
    <img src="https://raw.githubusercontent.com/TaylorWon/ImageBed/master/img/DL/9_modal_1_autoencoder_003.png" style="zoom:40%"
</div>

<p>第一层的code可以当做原输入信号的第一个表达，然后我们将第一层输出的code当成第二层的输入信号，同样进行最小化重构误差，就会得到第二层的参数，并且得到第二层输入的code,也就是原输入的第二个表达。其他层就同样的方法进行复制即可。（训练当前层时，前面层的参数都是固定的，并且他们的decoder已经没用了，都不需要了）。</p>
<p><strong>3）有监督微调</strong></p>
<p>经过上面的方法，我们就可以得到很多层了。每一层都会得到原始输入的不同的表达。当然了，我们觉得它是越抽象越好，就像人的视觉系统一样。</p>
<p>到这里，AutoEncoder还不能来分类数据，因为它还没有学习如何去连结一个输入和一个类。它只是学会了如何去重构或者复现它的输入而已。或者说，它只是学习获得了一个可以良好代表输入的特征，这个特征可以最大程度上代表原输入信号。那么为了实现分类，我们就可以在AutoEncoder的最顶层的编码层添加一个分类器(例如罗杰斯特回归、SVM等)，然后通过标准的多层神经网络的监督训练方法(梯度下降法)去训练。</p>
<p>也就是说，这时候，我们需要将最后层的特征code输入到最后的分类器，通过有标签样本，通过监督学习进行微调，这也分为两种，一种是只调整分类器(黑色部分)：</p>
<div align="center">
    <img src="https://raw.githubusercontent.com/TaylorWon/ImageBed/master/img/DL/9_modal_1_autoencoder_004.png" style="zoom:40%"
</div>


<p>另一种是通过有标签样本，微调整个系统：</p>
<div align="center">
    <img src="https://raw.githubusercontent.com/TaylorWon/ImageBed/master/img/DL/9_modal_1_autoencoder_005.png" style="zoom:40%"
</div>

<p>一旦监督训练完成，整个网络就可以用来分类了。神经网络的最顶层可以作为一个线性分类器，然后我们可以用一个更好性能的分类器去取代它。</p>
<p><strong>Sparse AutoEnCoder 稀疏自动编码器</strong></p>
<p>如果我们在AutoEncoder的基础上加上L1的Regularity限制(L1主要是约束每一层中的节点中大部分都要为0，只有少数不为0，这就是Sparse名字的来源)，我们就可以得到Sparse AutoEncoder法。</p>
<div align="center">
    <img src="https://raw.githubusercontent.com/TaylorWon/ImageBed/master/img/DL/9_modal_1_sparseautocoder_001.png" style="zoom:40%"
</div>


<p>如上图，就是限制每次得到的表达的code尽量稀疏，因为稀疏的表达往往比其他的表达要有效。</p>
<p><strong>Denoising AutoEncoders降噪自动编码器</strong></p>
<div align="center">
    <img src="https://raw.githubusercontent.com/TaylorWon/ImageBed/master/img/DL/9_modal_1_denoisingautocoder_001.png" style="zoom:40%"
</div>

<p>降噪自动编码器是在自动编码器的基础上，训练数据加入噪声，所以自动编码器必须学习去除这种噪声而获得真正的没有被噪声污染过的输入。这就要迫使编码器去学习输入信号的更加鲁棒的表达，这也是它的泛化能力比一般编码器强的原因。降噪自动编码器可通过梯度下降算法去训练。</p>
<h4 id="9-2-Sparse-Coding稀疏编码"><a href="#9-2-Sparse-Coding稀疏编码" class="headerlink" title="9.2. Sparse Coding稀疏编码"></a>9.2. Sparse Coding稀疏编码</h4><p>如果我们把输出必须和输入相等的限制放松，同时利用线性代数中基的概念，即$O=a_1<em>\phi_1+a_2<em>\phi_2+…+a_n</em>\phi_n$, $\phi_i$是基矢，$a_i$是系数，我们可以得到这样一个优化问题：<br>$$<br>Min|I-O|, 其中I表示输入，O表示输出<br>$$<br>通过求解这个最优化式子，我们可以求得系数$a_i$和基矢$\phi_i$，这些系数和基矢就是输入的另一种近似表达。<br>$$<br>x = \sum_{i=1}^k a_i\phi_i<br>$$<br>因此，它们可以用来表达输入I，这个过程也是自动学习得到的。如果我们在上述式子上加上L1的Regularity限制，可得到:<br>$$<br>Min|I-O| + u</em>(|a_1|+|a_2|+…+|a_n|)<br>$$<br>这种方法被称为Sparse Coding。就是将一个信号表示为一组基的线性组合，而且要求只需要较少的几个基就可以将信号表示出来。</p>
<p>“稀疏性”定义为：只有很少的几个非零元素或者只有很少的几个远大于零的元素。要求系数$a_i$是稀疏的意思是：对于一组输入向量，我们只想有尽可能少的几个系数远大于零。选择使用具有稀疏性的分量来表示我们的输入数据是有原因的，因为绝大多数的感官数据，比如自然图像，可以被表示成少量基本元素的叠加，在图像中这些元素可以是面或者线。</p>
<p>稀疏编码算法是一种无监督学习方法，它用来寻找一组”超完备”基向量来更高效地表示样本数据。<a href="http://deeplearning.stanford.edu/wiki/index.php/%E7%A8%80%E7%96%8F%E7%BC%96%E7%A0%81" target="_blank" rel="noopener">(详细过程请参考：UFLDL Tutorial稀疏编码)</a></p>
<h4 id="9-3-Restricted-Boltzmann-Machine-RBM-限制玻尔兹曼机"><a href="#9-3-Restricted-Boltzmann-Machine-RBM-限制玻尔兹曼机" class="headerlink" title="9.3. Restricted Boltzmann Machine(RBM)限制玻尔兹曼机"></a>9.3. Restricted Boltzmann Machine(RBM)限制玻尔兹曼机</h4><p>假设有一个二部图，每一层的节点之间没有链接，一层是可视层，即输入数据层(v)，一层是隐藏层(h)，如果假设所有的节点都是随机二值变量节点(只能取0或者1值)，同时假设全概率分布$p(v,h)$满足Boltzmann分布，我们成这个模型为Restricted Boltzmann Machine。</p>
<div align="center">
    <img src="https://raw.githubusercontent.com/TaylorWon/ImageBed/master/img/DL/9_modal_3_rbm_001.png" style="zoom:40%"
</div>

<p>首先，这个模型是二部图，所以在已知v的情况下，所有的隐藏节点之间是条件独立的(因为节点之间不存在连接)，即$p(h|v)=p(h_1|v)…p(h_n|v)$。同理，在已知隐藏层h的情况下，所有的可视节点都是条件独立的。<br>同时，又由于所有的v和h满足Boltzmann分布，因此，当输入v的时候，通过$p(h|v)$可以得到隐藏层h，而得到隐藏层h之后，通过$p(v|h)$又能得到可视层，通过调整参数，使得从隐藏层得到的可视层v1与原来的可视层v如果一样，那么得到的隐藏层就是可视层另外的一种表达，因此隐藏层可以作为可视层输入数据的特征。</p>
<div align="center">
    <img src="https://raw.githubusercontent.com/TaylorWon/ImageBed/master/img/DL/9_modal_3_rbm_002.png" style="zoom:40%"
</div>


<p>如果我们将隐藏层的层数增加，我们就可以得到Deep Boltzmann Machine(DBM)。如果我们在靠近可视层的部分使用贝叶斯信念网络(即有向图模型)，而在最远离可视层的部分使用Restricted Boltzmann Machine，我们可以得到Deep Belief Net(DBN)。</p>
<div align="center">
    <img src="https://raw.githubusercontent.com/TaylorWon/ImageBed/master/img/DL/9_modal_3_rbm_003.png" style="zoom:40%"
</div>

<h4 id="9-4-Deep-Belief-Networks深信度网络"><a href="#9-4-Deep-Belief-Networks深信度网络" class="headerlink" title="9.4. Deep Belief Networks深信度网络"></a>9.4. Deep Belief Networks深信度网络</h4><p>DBNs是一个概率生成模型，与传统的判别模型的神经网络相对，生成模型是建立一个观察数据和标签之间的联合分布，对$p(Observation|Label)$和$p(Label|Observation)$都做了评估，而判别模型仅仅评估了后者而已，也就是$p(Label|Observation)$。<br>对于在深度神经网络应用传统的BP算法的时候，DNBs遇到了以下的问题：</p>
<ul>
<li>需要为训练提供一个有标签的样本集</li>
<li>学习过程较慢</li>
<li>不适当的参数选择会导致学习收敛于局部最优解</li>
</ul>
<div align="center">
    <img src="https://raw.githubusercontent.com/TaylorWon/ImageBed/master/img/DL/9_modal_4_dbns_001.png" style="zoom:40%"
</div>



<p>DBNs由多个限制玻尔兹曼机层(RBM)组成，一个典型的神经网络类型如下图所示。</p>
<div align="center">
    <img src="https://raw.githubusercontent.com/TaylorWon/ImageBed/master/img/DL/9_modal_4_dbns_002.png" style="zoom:40%"
</div>



<p>这些网络被“限制”为一个可视层和一个隐层，层间存在连接，但层内的单元间不存在连接，隐层单元被训练去捕捉在可视层变表现出来的高阶数据的相关性。</p>
<h4 id="9-5-Convolutional-Neural-Networks卷积神经网络"><a href="#9-5-Convolutional-Neural-Networks卷积神经网络" class="headerlink" title="9.5. Convolutional Neural Networks卷积神经网络"></a>9.5. Convolutional Neural Networks卷积神经网络</h4><p>卷积神经网络是人工神经网络的一种，已成为当前语音分析和图像识别领域的研究热点。它的权值共享网络结构使之更类似于生物神经网络，降低了网络模型的复杂度，减少了权值的数量。卷积网络是为识别二维形状而特殊设计的一个多层感知器，这种网络结构对平移、比例缩放、倾斜或者共他形式的变形具有高度不变性。</p>
<p>CNNs是第一个真正成功训练多层网络结构的学习算法。它利用空间关系减少需要学习的参数数目以提高一般前向BP算法的训练性能。在CNN中，图像的一小部分(局部感受区域)作为层级结构的最底层的输入，信息再依次传输到不同的层，每层通过一个数字滤波器去获得观测数据的最显著的特征。这个方法能够获取对平移、缩放和旋转不变的观测数据的显著特征，因为图像的局部感受区域允许神经元或者处理单元可以访问到最基础的特征，例如定向边缘或者角点。</p>
<p><strong>1）卷积神经网络的历史</strong></p>
<p>通常神经认知机包含两类神经元，即承担特征抽取的S-元和抗变形的C-元。S-元中涉及两个重要参数，即感受野与阈值参数，前者确定输入连接的数目，后者则控制对特征子模式的反应程度。</p>
<p><strong>2）卷积神经网络的网络结构</strong></p>
<p>卷积神经网络是一个多层的神经网络，每层由多个二维平面组成，而每个平面由多个独立神经元组成。</p>
<div align="center">
    <img src="https://raw.githubusercontent.com/TaylorWon/ImageBed/master/img/DL/9_modal_5_cnn_001.png" style="zoom:40%"
</div>

<p>一般地，C层为特征提取层，每个神经元的输入与前一层的局部感受野相连，并提取该局部的特征，一旦该局部特征被提取后，它与其他特征间的位置关系也随之确定下来。S层是特征映射层，网络的每个计算层由多个特征映射组成，每个特征映射为一个平面，平面上所有神经元的权值相等。特征映射结构采用影响函数核小的sigmoid函数作为卷积网络的激活函数，使得特征映射具有唯一不变性。</p>
<p>此外，由于一个映射面上的神经元共享权值，因而减少了网络自由参数的个数，降低了网络参数选择的复杂度。卷积神经网络中的每一个特征提取层C-层都紧跟着一个用来求局部平均与二次提取的计算层S-层，这种特有的两次特征提取结构使网络在识别时对输入样本有较高的畸变容忍能力。</p>
<h3 id="十-总结与展望"><a href="#十-总结与展望" class="headerlink" title="十. 总结与展望"></a>十. 总结与展望</h3><h4 id="Deep-Learning总结"><a href="#Deep-Learning总结" class="headerlink" title="Deep Learning总结"></a>Deep Learning总结</h4><p>深度学习是关于自动学习要建模的数据的潜在(隐含)分布的多层(复杂)表达的算法。深度学习算法自动的提取分类需要的低层次或者高层次特征。高层次特征，是指该特征可以分级(层级)地依赖其他特征。</p>
<p>Deep Learnign能够得到更好地表示数据的feature，同时由于建模的层次、参数很多，capacity足够，因此，建模有能力表示大规模数据。此外，从模式识别特征和分类器的角度，deep learning框架将feature和分类器结合在一个框架中，用数据去学习feature，在使用中减少了手工设计feature的巨大工作量，因此，不仅仅效果可以更好，而且使用起来也有很多方便之处。因此，是十分值得关注的一套框架，每个做ML的人都应该关注了解一下。</p>
<p>当然，deep learning本身也不是完美的，也不是解决世间任何ML问题的利器，不应该被放大到一个无所不能的程度。</p>
<h4 id="Deep-Learning未来"><a href="#Deep-Learning未来" class="headerlink" title="Deep Learning未来"></a>Deep Learning未来</h4><p>深度学习目前仍有大量工作需要研究。目前的关注点还是从机器学习的领域借鉴一些可以在深度学习使用的方法，特别是降维领域。</p>
<p>探索新的特征提取模型是值得深入研究的内容。此外有效的可并行训练算法也是值得研究的一个方向。</p>
<div style="page-break-after:always;"> </div>



<h4 id="什么是机器学习？"><a href="#什么是机器学习？" class="headerlink" title="什么是机器学习？"></a>什么是机器学习？</h4><p>机器学习是一种概念：不需要写任何与问题有关的特定代码，泛型算法(Generic Algorithms)就能告诉你一些关于你数据的有趣结论。不用编码，将数据输入泛型算法当中，就会在数据的基础上建立出它自己的逻辑。</p>
<h4 id="两类机器学习算法"><a href="#两类机器学习算法" class="headerlink" title="两类机器学习算法"></a>两类机器学习算法</h4><p>机器学习算法分为两大类：==监督式学习(supervised learning)==和==非监督式学习(unsupervised learning)==。</p>
<h5 id="监督式学习"><a href="#监督式学习" class="headerlink" title="监督式学习"></a>监督式学习</h5><p>首先，有了训练数据。然后使用这些训练数据，来进行后面的预测计算。</p>
<h5 id="非监督式学习"><a href="#非监督式学习" class="headerlink" title="非监督式学习"></a>非监督式学习</h5><h4 id="学习的定义"><a href="#学习的定义" class="headerlink" title="学习的定义"></a>学习的定义</h4><p>机器在少量样本数据的基础上找出一个公式来解决特定的问题。</p>
<h4 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h4><p><a href="https://www.stoodnt.com/blog/ann-neural-networks-deep-learning-machine-learning-artificial-intelligence-differences/" target="_blank" rel="noopener">Demystifying NN,DL,ML,and AI</a></p>

      
      <!-- reward -->
      
    </div>
    
    
      <!-- copyright -->
      
        <div class="declare">
          <ul class="post-copyright">
            <li>
              <i class="ri-copyright-line"></i>
              <strong>版权声明： </strong s>
              本博客所有文章除特别声明外，均采用 <a href="https://www.apache.org/licenses/LICENSE-2.0.html" rel="external nofollow"
                target="_blank">Apache License 2.0</a> 许可协议。转载请注明出处！
            </li>
          </ul>
        </div>
        
    <footer class="article-footer">
      
          
<div class="share-btn">
      <span class="share-sns share-outer">
        <i class="ri-share-forward-line"></i>
        分享
      </span>
      <div class="share-wrap">
        <i class="arrow"></i>
        <div class="share-icons">
          
          <a class="weibo share-sns" href="javascript:;" data-type="weibo">
            <i class="ri-weibo-fill"></i>
          </a>
          <a class="weixin share-sns wxFab" href="javascript:;" data-type="weixin">
            <i class="ri-wechat-fill"></i>
          </a>
          <a class="qq share-sns" href="javascript:;" data-type="qq">
            <i class="ri-qq-fill"></i>
          </a>
          <a class="douban share-sns" href="javascript:;" data-type="douban">
            <i class="ri-douban-line"></i>
          </a>
          <!-- <a class="qzone share-sns" href="javascript:;" data-type="qzone">
            <i class="icon icon-qzone"></i>
          </a> -->
          
          <a class="facebook share-sns" href="javascript:;" data-type="facebook">
            <i class="ri-facebook-circle-fill"></i>
          </a>
          <a class="twitter share-sns" href="javascript:;" data-type="twitter">
            <i class="ri-twitter-fill"></i>
          </a>
          <a class="google share-sns" href="javascript:;" data-type="google">
            <i class="ri-google-fill"></i>
          </a>
        </div>
      </div>
</div>

<div class="wx-share-modal">
    <a class="modal-close" href="javascript:;"><i class="ri-close-circle-line"></i></a>
    <p>扫一扫，分享到微信</p>
    <div class="wx-qrcode">
      <img src="//api.qrserver.com/v1/create-qr-code/?size=150x150&data=https://taylorwon.github.io/2020/cka0u3h7e0002awgx2b7g2ekv/" alt="微信分享二维码">
    </div>
</div>

<div id="share-mask"></div>
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/%E6%8A%80%E6%9C%AF/" rel="tag">技术</a></li></ul>


    </footer>

  </div>

  
  
  <nav class="article-nav">
    
      <a href="/2020/cka0u3h7m0008awgxhyr24fg9/" class="article-nav-link">
        <strong class="article-nav-caption">上一篇</strong>
        <div class="article-nav-title">
          
            Deep Convolutional GANs with PyTorch
          
        </div>
      </a>
    
    
      <a href="/2020/cka0u3h7j0006awgxeh5j75im/" class="article-nav-link">
        <strong class="article-nav-caption">下一篇</strong>
        <div class="article-nav-title">Deep Learning 学习笔记</div>
      </a>
    
  </nav>


  

  
  
<!-- valine评论 -->
<div id="vcomments-box">
    <div id="vcomments">
    </div>
</div>
<script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
<script src='https://cdn.jsdelivr.net/npm/valine@1.3.10/dist/Valine.min.js'></script>
<script>
    new Valine({
        el: '#vcomments',
        app_id: 'chaSYi8FMdJBwzIBpxeNjqWC-gzGzoHsz',
        app_key: 'PqqkLYgPkHvH1BmyQqySWnSK',
        path: window.location.pathname,
        notify: 'false',
        verify: 'false',
        avatar: 'mp',
        placeholder: '给我的文章加点评论吧~',
        recordIP: true
    });
    const infoEle = document.querySelector('#vcomments .info');
    if (infoEle && infoEle.childNodes && infoEle.childNodes.length > 0) {
        infoEle.childNodes.forEach(function (item) {
            item.parentNode.removeChild(item);
        });
    }
</script>
<style>
    #vcomments-box {
        padding: 5px 30px;
    }

    @media screen and (max-width: 800px) {
        #vcomments-box {
            padding: 5px 0px;
        }
    }

    #vcomments-box #vcomments {
        background-color: #fff;
    }

    .v .vlist .vcard .vh {
        padding-right: 20px;
    }

    .v .vlist .vcard {
        padding-left: 10px;
    }
</style>

  

  
  
  

</article>
</section>
      <footer class="footer">
  <div class="outer">
    <ul class="list-inline">
      <li>
        &copy;
        2020
        Taylor Won
      </li>
      <li>
        
          Powered by
        
        
        <a href="https://hexo.io" target="_blank">Hexo</a> Theme <a href="https://github.com/Shen-Yu/hexo-theme-ayer" target="_blank">Ayer</a>
        
      </li>
    </ul>
    <ul class="list-inline">
      <li>
        
        
        <span>
  <i>PV:<span id="busuanzi_value_page_pv"></span></i>
  <i>UV:<span id="busuanzi_value_site_uv"></span></i>
</span>
        
      </li>
      <li>
        <!-- cnzz统计 -->
        
        <script type="text/javascript" src='https://s9.cnzz.com/z_stat.php?id=1278069914&amp;web_id=1278069914'></script>
        
      </li>
    </ul>
  </div>
</footer>
    <div class="to_top">
        <div class="totop" id="totop">
  <i class="ri-arrow-up-line"></i>
</div>
      </div>
    </main>
      <aside class="sidebar">
        <button class="navbar-toggle"></button>
<nav class="navbar">
  
  <div class="logo">
    <a href="/"><img src="/images/ayer-side.svg" alt="��"></a>
  </div>
  
  <ul class="nav nav-main">
    
    <li class="nav-item">
      <a class="nav-item-link" href="/">主页</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/archives">归档</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/categories">分类</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/tags">标签</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/tags/%E9%9F%B3%E4%B9%90/">音乐</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/">科研</a>
    </li>
    
    <li class="nav-item">
      <a class="nav-item-link" href="/2020/about">关于我</a>
    </li>
    
  </ul>
</nav>
<nav class="navbar navbar-bottom">
  <ul class="nav">
    <li class="nav-item">
      
      <a class="nav-item-link nav-item-search"  title="Search">
        <i class="ri-search-line"></i>
      </a>
      
      
      <a class="nav-item-link" target="_blank" href="/atom.xml" title="RSS Feed">
        <i class="ri-rss-line"></i>
      </a>
      
    </li>
  </ul>
</nav>
<div class="search-form-wrap">
  <div class="local-search local-search-plugin">
  <input type="search" id="local-search-input" class="local-search-input" placeholder="Search...">
  <div id="local-search-result" class="local-search-result"></div>
</div>
</div>


      </aside>
      <div id="mask"></div>

<!-- #reward -->
<div id="reward">
  <span class="close"><i class="ri-close-line"></i></span>
  <p class="reward-p"><i class="ri-cup-line"></i>请我喝杯咖啡吧~</p>
  <div class="reward-box">
    
    
  </div>
</div>
      
<script src="/js/jquery-2.0.3.min.js"></script>


<script src="/js/jquery.justifiedGallery.min.js"></script>


<script src="/js/lazyload.min.js"></script>


<script src="/js/busuanzi-2.3.pure.min.js"></script>


<script src="/js/share.js"></script>



<script src="/fancybox/jquery.fancybox.min.js"></script>




<script>
  try {
    var typed = new Typed("#subtitle", {
    strings: ['不够完美又何妨','万物皆有裂隙','那是光进来的地方'],
    startDelay: 0,
    typeSpeed: 200,
    loop: true,
    backSpeed: 100,
    showCursor: true
    });
  } catch (err) {
  }
  
</script>




<script src="/js/tocbot.min.js"></script>

<script>
  // Tocbot_v4.7.0  http://tscanlin.github.io/tocbot/
  tocbot.init({
    tocSelector: '.tocbot',
    contentSelector: '.article-entry',
    headingSelector: 'h1, h2, h3, h4, h5, h6',
    hasInnerContainers: true,
    scrollSmooth: true,
    scrollContainer:'main',
    positionFixedSelector: '.tocbot',
    positionFixedClass: 'is-position-fixed',
    fixedSidebarOffset: 'auto',
    onClick: (e) => {
      $('.toc-link').removeClass('is-active-link');
      $(`a[href=${e.target.hash}]`).addClass('is-active-link');
      $(e.target.hash).scrollIntoView();
      return false;
    }
  });
</script>


<script>
  var ayerConfig = {
    mathjax: false
  }
</script>


<script src="/js/ayer.js"></script>


<script src="https://cdn.jsdelivr.net/npm/jquery-modal@0.9.2/jquery.modal.min.js"></script>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/jquery-modal@0.9.2/jquery.modal.min.css">


<!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    <!-- Background of PhotoSwipe. 
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>

    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">

        <!-- Container that holds slides. 
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                <!--  Controls are self-explanatory. Order can be changed. -->

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" style="display:none" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                <!-- Preloader demo http://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                        <div class="pswp__preloader__cut">
                            <div class="pswp__preloader__donut"></div>
                        </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div>

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.css">
<script src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js"></script>

<script>
    function viewer_init() {
        let pswpElement = document.querySelectorAll('.pswp')[0];
        let $imgArr = document.querySelectorAll(('.article-entry img:not(.reward-img)'))

        $imgArr.forEach(($em, i) => {
            $em.onclick = () => {
                // slider展开状态
                // todo: 这样不好，后面改成状态
                if (document.querySelector('.left-col.show')) return
                let items = []
                $imgArr.forEach(($em2, i2) => {
                    let img = $em2.getAttribute('data-idx', i2)
                    let src = $em2.getAttribute('data-target') || $em2.getAttribute('src')
                    let title = $em2.getAttribute('alt')
                    // 获得原图尺寸
                    const image = new Image()
                    image.src = src
                    items.push({
                        src: src,
                        w: image.width || $em2.width,
                        h: image.height || $em2.height,
                        title: title
                    })
                })
                var gallery = new PhotoSwipe(pswpElement, PhotoSwipeUI_Default, items, {
                    index: parseInt(i)
                });
                gallery.init()
            }
        })
    }
    viewer_init()
</script>




<script type="text/javascript" src="https://js.users.51.la/20544303.js"></script>
  </div>
</body>

</html>